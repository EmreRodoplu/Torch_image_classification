{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri dönüşümlerini tanımlayın (boyutlandırma, normalizasyon)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),# Görüntü boyutunu ayarlayın\n",
    "    transforms.ToTensor(),# Görüntüyü Tensor formatına dönüştürün\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # Normalize edin\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_image(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            img.load()\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "root_folder = \"PetImages_Train\"  # Verilerin bulunduğu klasörü belirtin\n",
    "dataset = datasets.ImageFolder(root=root_folder, transform=transform, is_valid_file=is_valid_image)\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset , batch_size=32 ,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cat': 0, 'Dog': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.4824, -0.5137, -0.5922,  ..., -0.7255, -0.6941, -0.7412],\n",
      "          [-0.6549, -0.5529, -0.5451,  ..., -0.6863, -0.6627, -0.6314],\n",
      "          [-0.6863, -0.5765, -0.5922,  ..., -0.6000, -0.4980, -0.5216],\n",
      "          ...,\n",
      "          [-0.4196, -0.4196, -0.5137,  ..., -0.3333, -0.3020, -0.3020],\n",
      "          [-0.4196, -0.5059, -0.6157,  ..., -0.3412, -0.3255, -0.3098],\n",
      "          [-0.4824, -0.4824, -0.4118,  ..., -0.3490, -0.3490, -0.3412]],\n",
      "\n",
      "         [[-0.4510, -0.4902, -0.5686,  ..., -0.5843, -0.6078, -0.6941],\n",
      "          [-0.6392, -0.5373, -0.5216,  ..., -0.6078, -0.6314, -0.6157],\n",
      "          [-0.6784, -0.5608, -0.5765,  ..., -0.5843, -0.5059, -0.5137],\n",
      "          ...,\n",
      "          [-0.2078, -0.2078, -0.3255,  ..., -0.1922, -0.1608, -0.1686],\n",
      "          [-0.2000, -0.2941, -0.4353,  ..., -0.2000, -0.1373, -0.1686],\n",
      "          [-0.2549, -0.2627, -0.2235,  ..., -0.2078, -0.1608, -0.1922]],\n",
      "\n",
      "         [[-0.8353, -0.8431, -0.8980,  ..., -0.9529, -0.9373, -0.9529],\n",
      "          [-0.9373, -0.8510, -0.8431,  ..., -0.9216, -0.8980, -0.8745],\n",
      "          [-0.9216, -0.8431, -0.8902,  ..., -0.8353, -0.7412, -0.7961],\n",
      "          ...,\n",
      "          [-0.7961, -0.8039, -0.8588,  ..., -0.7176, -0.7098, -0.7176],\n",
      "          [-0.7961, -0.8667, -0.9294,  ..., -0.7569, -0.7412, -0.7020],\n",
      "          [-0.8824, -0.8745, -0.8118,  ..., -0.7647, -0.7647, -0.7255]]],\n",
      "\n",
      "\n",
      "        [[[-0.5843, -0.5922, -0.6000,  ...,  0.1922,  0.0118, -0.1373],\n",
      "          [-0.5216, -0.5294, -0.5529,  ..., -0.3961, -0.4196, -0.4118],\n",
      "          [-0.4824, -0.4980, -0.5294,  ..., -0.4588, -0.4510, -0.4353],\n",
      "          ...,\n",
      "          [ 0.1608,  0.1686,  0.1765,  ..., -0.5922, -0.5529, -0.5216],\n",
      "          [ 0.1686,  0.1686,  0.1843,  ..., -0.4745, -0.5059, -0.5216],\n",
      "          [ 0.1765,  0.1843,  0.2078,  ..., -0.3961, -0.4431, -0.4980]],\n",
      "\n",
      "         [[-0.6549, -0.6627, -0.6627,  ...,  0.3490,  0.1686,  0.0118],\n",
      "          [-0.5843, -0.5922, -0.6157,  ..., -0.2863, -0.3176, -0.3412],\n",
      "          [-0.5451, -0.5608, -0.5922,  ..., -0.3804, -0.3882, -0.3961],\n",
      "          ...,\n",
      "          [-0.0039,  0.0039,  0.0196,  ..., -0.5451, -0.4902, -0.4510],\n",
      "          [ 0.0118,  0.0431,  0.0667,  ..., -0.4431, -0.4745, -0.4588],\n",
      "          [ 0.0275,  0.0824,  0.1294,  ..., -0.3647, -0.4196, -0.4275]],\n",
      "\n",
      "         [[-0.8980, -0.9137, -0.9529,  ..., -0.1922, -0.3804, -0.5294],\n",
      "          [-0.8510, -0.8745, -0.9059,  ..., -0.6627, -0.6784, -0.6549],\n",
      "          [-0.8510, -0.8667, -0.8824,  ..., -0.6471, -0.6471, -0.6784],\n",
      "          ...,\n",
      "          [ 0.0588,  0.0510,  0.0431,  ..., -0.4588, -0.3961, -0.3333],\n",
      "          [ 0.0431,  0.0824,  0.1137,  ..., -0.3647, -0.3569, -0.3412],\n",
      "          [ 0.0353,  0.1294,  0.1843,  ..., -0.3255, -0.3176, -0.3255]]],\n",
      "\n",
      "\n",
      "        [[[-0.5059, -0.5059, -0.4902,  ...,  0.0902,  0.0588, -0.0275],\n",
      "          [-0.5216, -0.5216, -0.5059,  ...,  0.0824,  0.0745,  0.0353],\n",
      "          [-0.5373, -0.5373, -0.5216,  ...,  0.0824,  0.0824,  0.1294],\n",
      "          ...,\n",
      "          [ 0.0510,  0.0745,  0.0824,  ..., -0.1059, -0.0588,  0.0118],\n",
      "          [ 0.0431,  0.0353,  0.0745,  ..., -0.0902, -0.0902, -0.0118],\n",
      "          [ 0.0431,  0.0353,  0.0510,  ..., -0.1137, -0.0745, -0.0196]],\n",
      "\n",
      "         [[-0.8745, -0.8745, -0.8588,  ..., -0.5608, -0.5373, -0.3804],\n",
      "          [-0.8824, -0.8824, -0.8667,  ..., -0.5686, -0.5608, -0.5137],\n",
      "          [-0.8824, -0.8824, -0.8745,  ..., -0.5843, -0.5765, -0.5608],\n",
      "          ...,\n",
      "          [ 0.0431,  0.0588,  0.0745,  ..., -0.0588, -0.0353, -0.0039],\n",
      "          [ 0.0431,  0.0353,  0.0745,  ..., -0.0431, -0.0745, -0.0353],\n",
      "          [ 0.0431,  0.0353,  0.0510,  ..., -0.0667, -0.0588, -0.0510]],\n",
      "\n",
      "         [[-0.8118, -0.8118, -0.7961,  ..., -0.3804, -0.3725, -0.3020],\n",
      "          [-0.8196, -0.8196, -0.8118,  ..., -0.3882, -0.3804, -0.3647],\n",
      "          [-0.8275, -0.8275, -0.8196,  ..., -0.3882, -0.3882, -0.3647],\n",
      "          ...,\n",
      "          [-0.2471, -0.2314, -0.2235,  ..., -0.2941, -0.3020, -0.2627],\n",
      "          [-0.2392, -0.2471, -0.2078,  ..., -0.2784, -0.3333, -0.3020],\n",
      "          [-0.2392, -0.2471, -0.2314,  ..., -0.3020, -0.3176, -0.3255]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2627,  0.2549,  0.2784,  ..., -0.2000, -0.2157, -0.2314],\n",
      "          [ 0.2784,  0.2627,  0.2941,  ..., -0.1686, -0.1765, -0.1686],\n",
      "          [ 0.2549,  0.2706,  0.3412,  ..., -0.1608, -0.1608, -0.1529],\n",
      "          ...,\n",
      "          [-0.7882, -0.7804, -0.7804,  ..., -0.2549, -0.2627, -0.3020],\n",
      "          [-0.7804, -0.7725, -0.7961,  ..., -0.2784, -0.2863, -0.3098],\n",
      "          [-0.7804, -0.7961, -0.7882,  ..., -0.2863, -0.2784, -0.3333]],\n",
      "\n",
      "         [[ 0.0667,  0.0667,  0.1059,  ..., -0.3490, -0.3569, -0.3569],\n",
      "          [ 0.0745,  0.0745,  0.1294,  ..., -0.3333, -0.3412, -0.3333],\n",
      "          [ 0.0431,  0.0824,  0.1686,  ..., -0.3412, -0.3490, -0.3490],\n",
      "          ...,\n",
      "          [-0.8275, -0.8196, -0.8275,  ..., -0.3882, -0.3961, -0.4039],\n",
      "          [-0.8196, -0.8118, -0.8353,  ..., -0.3961, -0.4275, -0.4353],\n",
      "          [-0.8196, -0.8353, -0.8275,  ..., -0.4039, -0.4275, -0.4431]],\n",
      "\n",
      "         [[-0.0353, -0.0275,  0.0196,  ..., -0.4510, -0.4824, -0.5137],\n",
      "          [-0.0196, -0.0118,  0.0588,  ..., -0.4275, -0.4275, -0.4588],\n",
      "          [-0.0353,  0.0118,  0.1216,  ..., -0.4196, -0.4118, -0.4510],\n",
      "          ...,\n",
      "          [-0.8745, -0.8431, -0.8353,  ..., -0.4353, -0.4588, -0.4588],\n",
      "          [-0.8588, -0.8431, -0.8667,  ..., -0.4588, -0.4667, -0.4745],\n",
      "          [-0.8510, -0.8667, -0.8588,  ..., -0.4588, -0.4588, -0.5059]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0118, -0.1451,  0.0353,  ...,  0.3255,  0.3725,  0.3804],\n",
      "          [-0.0196, -0.0667,  0.1373,  ...,  0.2941,  0.3490,  0.3490],\n",
      "          [-0.0353,  0.0745,  0.1922,  ...,  0.0588,  0.1294,  0.1059],\n",
      "          ...,\n",
      "          [-0.0824,  0.1059,  0.2000,  ..., -0.0431, -0.0745, -0.0588],\n",
      "          [ 0.1137,  0.2078,  0.2784,  ..., -0.0902, -0.0667, -0.1137],\n",
      "          [ 0.3804,  0.3020,  0.1529,  ..., -0.0353, -0.0667, -0.1294]],\n",
      "\n",
      "         [[ 0.0118, -0.1843, -0.0039,  ...,  0.3569,  0.3961,  0.4353],\n",
      "          [ 0.0118, -0.0745,  0.1059,  ...,  0.3255,  0.3725,  0.3804],\n",
      "          [ 0.0431,  0.0980,  0.1765,  ...,  0.0824,  0.1451,  0.1216],\n",
      "          ...,\n",
      "          [-0.2157, -0.0196,  0.0824,  ..., -0.1294, -0.1608, -0.1765],\n",
      "          [ 0.0196,  0.1373,  0.2000,  ..., -0.1765, -0.1529, -0.2314],\n",
      "          [ 0.3176,  0.2549,  0.0824,  ..., -0.1216, -0.1529, -0.2392]],\n",
      "\n",
      "         [[-0.0980, -0.3020, -0.1137,  ...,  0.3490,  0.4353,  0.4902],\n",
      "          [-0.0980, -0.2000, -0.0118,  ...,  0.2706,  0.3255,  0.3569],\n",
      "          [-0.0824, -0.0510,  0.0353,  ..., -0.0431, -0.0039, -0.0118],\n",
      "          ...,\n",
      "          [-0.4275, -0.2784, -0.2392,  ..., -0.1608, -0.2000, -0.2000],\n",
      "          [-0.2627, -0.1451, -0.1216,  ..., -0.2078, -0.2000, -0.2706],\n",
      "          [-0.0588, -0.0745, -0.2235,  ..., -0.1529, -0.2000, -0.3020]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8510,  0.9529,  0.6549,  ...,  0.0196,  0.0039, -0.0039],\n",
      "          [ 0.7647,  0.9137,  0.7647,  ...,  0.0118,  0.0039,  0.0118],\n",
      "          [ 0.6314,  0.8980,  0.8902,  ...,  0.0118,  0.0118,  0.0196],\n",
      "          ...,\n",
      "          [-0.3961, -0.4353, -0.3255,  ..., -0.1608, -0.1686, -0.1529],\n",
      "          [-0.4353, -0.4039, -0.2941,  ..., -0.1686, -0.1765, -0.1843],\n",
      "          [-0.4431, -0.3255, -0.2314,  ..., -0.1843, -0.2000, -0.1843]],\n",
      "\n",
      "         [[ 0.8353,  0.9294,  0.6157,  ..., -0.1608, -0.1843, -0.1922],\n",
      "          [ 0.7255,  0.8667,  0.7098,  ..., -0.1686, -0.1843, -0.1765],\n",
      "          [ 0.5765,  0.8431,  0.8353,  ..., -0.1686, -0.1765, -0.1686],\n",
      "          ...,\n",
      "          [-0.5451, -0.5843, -0.4745,  ..., -0.2863, -0.2941, -0.2784],\n",
      "          [-0.5922, -0.5608, -0.4431,  ..., -0.2941, -0.3020, -0.3098],\n",
      "          [-0.5843, -0.4588, -0.3725,  ..., -0.3098, -0.3255, -0.3176]],\n",
      "\n",
      "         [[ 0.8588,  0.9608,  0.6471,  ..., -0.0824, -0.0824, -0.0824],\n",
      "          [ 0.8039,  0.9216,  0.7804,  ..., -0.0902, -0.0824, -0.0667],\n",
      "          [ 0.6706,  0.9137,  0.8902,  ..., -0.0902, -0.0745, -0.0588],\n",
      "          ...,\n",
      "          [-0.4667, -0.5059, -0.4118,  ..., -0.2000, -0.2078, -0.1922],\n",
      "          [-0.5216, -0.4980, -0.3961,  ..., -0.2078, -0.2157, -0.2157],\n",
      "          [-0.5294, -0.4118, -0.3255,  ..., -0.2157, -0.2235, -0.2078]]]])\n",
      "tensor([1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for input ,labels in dataloader:\n",
    "    print(input)\n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN modelini oluşturun\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1),  # 3 kanal giriş, 16 çıkış, 3x3 çekirdek\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 2x2 maksimum havuzlama\n",
    "            nn.Conv2d(16, 32, 3, padding=1),  # 16 kanal giriş, 32 çıkış, 3x3 çekirdek\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),  # 32 kanal giriş, 64 çıkış, 3x3 çekirdek\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),  # Düzleştirme işlemi\n",
    "            nn.Linear(64 * 16 * 16, 512),  # Tam bağlantılı katman\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Dropout katmanı (aşırı uyumu önlemek için)\n",
    "            nn.Linear(512, 2)  # İki sınıflı çıkış katmanı (kedi ve köpek)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Modeli oluşturun\n",
    "model = CNNModel().to(\"cuda\")\n",
    "\n",
    "# Kayıp fonksiyonunu ve optimizasyon yöntemini tanımlayın\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.6595098376274109\n",
      "Loss_data : 0.6595098376274109\n",
      "Loss_item : 0.6595098376274109\n",
      "Loss : 0.5590130686759949\n",
      "Loss_data : 0.5590130686759949\n",
      "Loss_item : 0.5590130686759949\n",
      "Loss : 0.5436583161354065\n",
      "Loss_data : 0.5436583161354065\n",
      "Loss_item : 0.5436583161354065\n",
      "Loss : 0.5218498706817627\n",
      "Loss_data : 0.5218498706817627\n",
      "Loss_item : 0.5218498706817627\n",
      "Loss : 0.48614782094955444\n",
      "Loss_data : 0.48614782094955444\n",
      "Loss_item : 0.48614782094955444\n",
      "Eğitim tamamlandı.\n"
     ]
    }
   ],
   "source": [
    "# Eğitim döngüsü\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs ,labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Loss : {loss}\")\n",
    "    print(f\"Loss_data : {loss.data}\")\n",
    "    print(f\"Loss_item : {loss.item()}\")\n",
    "\n",
    "print(\"Eğitim tamamlandı.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_path = \"C:/Users/emrer/Desktop/python-uygulamalar/catvsdog/catphoto_1.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.JpegImagePlugin.JpegImageFile"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_img = Image.open(cat_path)\n",
    "type(cat_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_animal = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),    \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_transform = transform_animal(cat_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_transform = cat_transform.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_transform = cat_transform.view(-1,3,128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 128, 128])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4717, -0.3605]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(model(cat_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,predicted = torch.max(model(cat_transform),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_path = \"C:/Users/emrer/Desktop/python-uygulamalar/catvsdog/dogphoto_2.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.JpegImagePlugin.JpegImageFile"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_img = Image.open(dog_path)\n",
    "type(dog_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_transform = transform_animal(dog_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_transform = dog_transform.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_transform = dog_transform.view(-1,3,128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1594,  1.1541]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(model(dog_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,predicted_2 = torch.max(model(dog_transform),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1], device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
